# Parcial Final Big Data
# Por: Jofre Eduardo Oliveros y Juan Pablo Blanco
# Universidad Sergio Arboleda

El presente proyecto tiene como objetivo desarrollar funciones en python que por medio de herramientas como aws glue, permitan extraer informaci√≥n precisa de sitios web para posteriormente escribir los resultados en distintos servicios de Amazon Web Services como lo son Athena y S3.


### 1. Workflow aws glue que realiza scrapping a eltiempo.com y a publimetro.comüì∞ 

[job1](Punto1/job1.py) cada dia descargar√° la p√°gina principal de El Tiempo y Publ√≠metro.

La informaci√≥n quedar√° en S3 con la estructura:

‚Ä¢ s3://bucket/headlines/raw/periodico=xxx/year=xxx/month=xxx/day=xxx

Una vez llegado el archivo a la carpeta raw, se activar√° a [job2](Punto1/job2.py) el cual leer√° los datos que llegaron utilizando Beautifulsoup. Este proceso va a extraer la categor√≠a, el titular y el enlace para cada noticia. Estos datos se deben guardar en un csv en la
siguiente ruta:

‚Ä¢ s3://bucket/headlines/final/periodico=xxx/year=xxx/month=xxx/day=xxx

Este archivo dispara a [job3](Punto1/job3.py) que descarga la noticia y lo guarda en:

‚Ä¢ s3://bucket/news/raw/periodico=xxx/year=xxx/month=xxx/day=xxx

### 2. Aplicaci√≥n en spark-streaming-kafka que permita determinar la variaci√≥n del precio de las acciones en tiempo real. üí≤üí≤üí≤üí≤üí≤

[productor.py](Punto2/productor.py) se encargar√° de leer enl dataset y extraer los precios de √©l, cada 4 segundos se enviar√° un nuevo precio hacia el consumidor.

[consumidor.py](Punto2/consumidor.py) se encargar√° de  mostrar el promedio hasta el momento, el m√°ximo y m√≠nimo hasta el momento en cada instante. Adem√°s mostrar√° una alerta cuando el precio est√° por encima o por debajo de 2 desviaciones est√°ndar de la media. Por √∫ltimo este programa escribirp√° la informaci√≥n en un bucket de S3.



### ...Esperamos que disfrutes el proyecto, cualquier comentario escribir a [juan.blanco01@correo.usa.edu.co] o a [jofre.oliveros01@correo.usa.edu.co] üòä
